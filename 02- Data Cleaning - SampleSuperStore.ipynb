{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<h1 style=\"color:white\" align=\"center\">Data Cleaning: Sample SuperStore</h1>\n",
    "\n",
    "![grf-bg.jpg](images/grf-bg.jpg)\n",
    "\n",
    "This is a second part of the Sample SuperStore, Pandas & Python EDA tutorial. If you haven't yet alreeady gone through the first part of this tutorial, I strongly encourage you to read the first part. A lot of fundemental aspects covering the basic instructions around Python and Pandas, much like loading the libraries and understanding the dataset in gengeral have already been covered. Given that this is a second part of this Jupyter notebook tutorial, we will try to clean-up the data from invalid values, and manipulate them further to our business needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Library\n",
    "\n",
    "Since we'll be starting again with a fresh new Jupyter Notebook file, we need to load-up the library again to our environment. On the first part of this tutorial, we have covered this aspect and it's basically a continuation from our previous tutorial. Once that you type the following `import pandas as pd` to your Jupyter Notebook, Pandas is loaded once again and is ready for some action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read CSV File \n",
    "\n",
    "The following code would imply these instructions\n",
    "\n",
    "- *`df_cleaned`* = is the name of the variable, that will be using throughout the example of this tutorial.\n",
    "- *`pd`* = stands for Panda\n",
    "- *`.read_csv`* = is a method within to read the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try to read from the new order dataset\n",
    "# df_cleaned = pd.read_csv('data/df_orders_exported.csv', index_col='Order ID')\n",
    "df_cleaned = pd.read_csv('data/df_orders_exported.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10800 entries, 0 to 10799\n",
      "Data columns (total 20 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Order ID      10800 non-null  object \n",
      " 1   OrderDate     9994 non-null   object \n",
      " 2   ShipDate      9994 non-null   object \n",
      " 3   ShipMode      9994 non-null   object \n",
      " 4   CustomerID    9994 non-null   object \n",
      " 5   CustomerName  9994 non-null   object \n",
      " 6   Segment       9994 non-null   object \n",
      " 7   Country       9994 non-null   object \n",
      " 8   City          9994 non-null   object \n",
      " 9   State         9994 non-null   object \n",
      " 10  PostalCode    9983 non-null   float64\n",
      " 11  Region        9994 non-null   object \n",
      " 12  ProductID     9994 non-null   object \n",
      " 13  Category      9994 non-null   object \n",
      " 14  SubCategory   9994 non-null   object \n",
      " 15  ProductName   9994 non-null   object \n",
      " 16  Sales         9994 non-null   float64\n",
      " 17  Quantity      9994 non-null   float64\n",
      " 18  Discount      9994 non-null   float64\n",
      " 19  Profit        9994 non-null   float64\n",
      "dtypes: float64(5), object(15)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_cleaned.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10800, 20)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the total rows and columns number\n",
    "df_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the total rows and columns default numbers.\n",
    "pd.set_option('display.max_columns', 21)\n",
    "pd.set_option('display.max_rows', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10800 entries, 0 to 10799\n",
      "Data columns (total 20 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Order ID      10800 non-null  object \n",
      " 1   OrderDate     9994 non-null   object \n",
      " 2   ShipDate      9994 non-null   object \n",
      " 3   ShipMode      9994 non-null   object \n",
      " 4   CustomerID    9994 non-null   object \n",
      " 5   CustomerName  9994 non-null   object \n",
      " 6   Segment       9994 non-null   object \n",
      " 7   Country       9994 non-null   object \n",
      " 8   City          9994 non-null   object \n",
      " 9   State         9994 non-null   object \n",
      " 10  PostalCode    9983 non-null   float64\n",
      " 11  Region        9994 non-null   object \n",
      " 12  ProductID     9994 non-null   object \n",
      " 13  Category      9994 non-null   object \n",
      " 14  SubCategory   9994 non-null   object \n",
      " 15  ProductName   9994 non-null   object \n",
      " 16  Sales         9994 non-null   float64\n",
      " 17  Quantity      9994 non-null   float64\n",
      " 18  Discount      9994 non-null   float64\n",
      " 19  Profit        9994 non-null   float64\n",
      "dtypes: float64(5), object(15)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Let's check the head dataset values.\n",
    "df_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order ID</th>\n",
       "      <th>OrderDate</th>\n",
       "      <th>ShipDate</th>\n",
       "      <th>ShipMode</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>CustomerName</th>\n",
       "      <th>Segment</th>\n",
       "      <th>Country</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>PostalCode</th>\n",
       "      <th>Region</th>\n",
       "      <th>ProductID</th>\n",
       "      <th>Category</th>\n",
       "      <th>SubCategory</th>\n",
       "      <th>ProductName</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA-2017-152156</td>\n",
       "      <td>2017-11-08</td>\n",
       "      <td>2017-11-11</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>CG-12520</td>\n",
       "      <td>Claire Gute</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>42420.0</td>\n",
       "      <td>South</td>\n",
       "      <td>FUR-BO-10001798</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Bookcases</td>\n",
       "      <td>Bush Somerset Collection Bookcase</td>\n",
       "      <td>261.96</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.9136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CA-2017-152156</td>\n",
       "      <td>2017-11-08</td>\n",
       "      <td>2017-11-11</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>CG-12520</td>\n",
       "      <td>Claire Gute</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>42420.0</td>\n",
       "      <td>South</td>\n",
       "      <td>FUR-CH-10000454</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Chairs</td>\n",
       "      <td>Hon Deluxe Fabric Upholstered Stacking Chairs,...</td>\n",
       "      <td>731.94</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>219.5820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10798</th>\n",
       "      <td>US-2018-155999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10799</th>\n",
       "      <td>US-2018-155999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10800 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Order ID   OrderDate    ShipDate      ShipMode CustomerID  \\\n",
       "0      CA-2017-152156  2017-11-08  2017-11-11  Second Class   CG-12520   \n",
       "1      CA-2017-152156  2017-11-08  2017-11-11  Second Class   CG-12520   \n",
       "...               ...         ...         ...           ...        ...   \n",
       "10798  US-2018-155999         NaN         NaN           NaN        NaN   \n",
       "10799  US-2018-155999         NaN         NaN           NaN        NaN   \n",
       "\n",
       "      CustomerName   Segment        Country       City     State  PostalCode  \\\n",
       "0      Claire Gute  Consumer  United States  Henderson  Kentucky     42420.0   \n",
       "1      Claire Gute  Consumer  United States  Henderson  Kentucky     42420.0   \n",
       "...            ...       ...            ...        ...       ...         ...   \n",
       "10798          NaN       NaN            NaN        NaN       NaN         NaN   \n",
       "10799          NaN       NaN            NaN        NaN       NaN         NaN   \n",
       "\n",
       "      Region        ProductID   Category SubCategory  \\\n",
       "0      South  FUR-BO-10001798  Furniture   Bookcases   \n",
       "1      South  FUR-CH-10000454  Furniture      Chairs   \n",
       "...      ...              ...        ...         ...   \n",
       "10798    NaN              NaN        NaN         NaN   \n",
       "10799    NaN              NaN        NaN         NaN   \n",
       "\n",
       "                                             ProductName   Sales  Quantity  \\\n",
       "0                      Bush Somerset Collection Bookcase  261.96       2.0   \n",
       "1      Hon Deluxe Fabric Upholstered Stacking Chairs,...  731.94       3.0   \n",
       "...                                                  ...     ...       ...   \n",
       "10798                                                NaN     NaN       NaN   \n",
       "10799                                                NaN     NaN       NaN   \n",
       "\n",
       "       Discount    Profit  \n",
       "0           0.0   41.9136  \n",
       "1           0.0  219.5820  \n",
       "...         ...       ...  \n",
       "10798       NaN       NaN  \n",
       "10799       NaN       NaN  \n",
       "\n",
       "[10800 rows x 20 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check wheter or not we have empty cells/records in our dataset.\n",
    "\n",
    "The following code would imply these instructions\n",
    "\n",
    "- *df_orders* = is the name of the variable, that will be using throughout the example of this tutorial.\n",
    "- *.info()* = is the method to print the coloumns data type and cells number in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_cleaning' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-1ce62811d46b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Let's print the columns data types, along with the NaN records in the dataset and the number of cells in them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_cleaning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_cleaning' is not defined"
     ]
    }
   ],
   "source": [
    "# Let's print the columns data types, along with the NaN records in the dataset and the number of cells in them.\n",
    "df_cleaning.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RangeIndex: **10.800** entries, from 0 to 10799.\n",
    "- Data columns (**total 21 columns**):\n",
    "\n",
    "Range index would give us information on how many rows on the dataset, while for the data column would give us information on how many columns available. For the **Non-Null Count number** would give us the Valid records number. So to identify the missing records/cell, would be to subtract the RangeIndex entries, with the remaining of the records available.\n",
    "\n",
    "And also, as you can see from the previous list, we need to change the following column data types, from:\n",
    "\n",
    "- OrderDate : *Object*\n",
    "- ShipDate : *Object*\n",
    "- PostalCode : *Object*\n",
    "\n",
    "to\n",
    "\n",
    "- OrderDate : *DateTime*\n",
    "- ShipDate : *DateTime*\n",
    "- PostalCode : *Object*\n",
    "\n",
    "Since those column don't have an appropriate data types definition yet. That's why we need to change them, so we could manipulate them better on the next session.\n",
    "\n",
    "The following code would imply these instructions\n",
    "- *df_orders* = is the name of the variable, that will be using throughout the example of this tutorial.\n",
    "- *.astype()* = is the method to display the data types from the dataset available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try to check, if the current dataset has any potential invalid data in them?\n",
    "\n",
    "The following code would imply these instructions\n",
    "\n",
    "- *df_cleaning* = is the name of the variable, that will be using throughout the example of this tutorial.\n",
    "- *.isnull()* = is the method name, to check if not we have any invalids values in the dataset.\n",
    "- Note = this method would result in *True* or *False* output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaning.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Clean-up the Invalid Records in The Dataset\n",
    "\n",
    "So that we know from the above table, we have rows of invalid values within our tables (indicated by the '*True*' values, and we wish to do further analysis in them, it'd be best to remove them so we could get finer overview with the remaining of the table values.\n",
    "\n",
    "The following code would imply these instructions:\n",
    "\n",
    "- *df_cleaning* = is the name of the variable, that will be using throughout the example of this tutorial.\n",
    "- *.dropna()* = is the method name, to remove the invalid records within our dataset.\n",
    "- *['OrderDate]* = is the coloumn that we wish to check the invalid values from.\n",
    "- *inplace=True* = since we'd like to have them in a new dataset, we need to pass the value set to '*True*', that way it'd reflect on the new dataset. Otherwise if we pass the value of '*False*', it only stays on the **memory storage**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, let's try to drop missing or invalied values.\n",
    "# df_cleaning.dropna(subset=['OrderDate'], inplace=True)\n",
    "df_cleaning.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's do a quick check with the recent dataset, if everything marks with 'False', then everything is clear!\n",
    "df_cleaning.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making changes to data!\n",
    "## Let's Add Additional Column Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try to create the Revenue Column!\n",
    "df_cleaning['Revenue'] = df_cleaning['Sales'] - df_cleaning['Profit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaning.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try to create the (Gross) Price Column!\n",
    "df_cleaning['GrossPrice'] = (df_cleaning['Revenue'] - df_cleaning['Profit']) / df_cleaning['Quantity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaning.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try to create the (Net)Price Column!\n",
    "df_cleaning['NetPrice'] = df_cleaning['GrossPrice'] - (df_cleaning['GrossPrice'] * df_cleaning['Discount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaning.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaning.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the coloumn, 'GrossPrice' & 'Price'!\n",
    "df_cleaning = df_cleaning.drop(columns=['GrossPrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting Dataset\n",
    "\n",
    "Once that we've satisfied with out results, let's export them a new CSV dataset, so we could work with them on the next notebook.\n",
    "\n",
    "*- df_cleaning* = is the name of the variable, that will be using throughout the example of this tutorial.\n",
    "*- .to_csv* = is the export method to a CSV dataset.\n",
    "\n",
    "### From let's import them from previous superstore.csv to df_orders.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaning.to_csv('df_cleaning.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
