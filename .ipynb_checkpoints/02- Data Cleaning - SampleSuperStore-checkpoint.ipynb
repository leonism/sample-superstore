{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:black\" align=\"center\">Data Cleaning: Sample SuperStore</h1>\n",
    "\n",
    "![grf-bg.jpg](images/grf-bg.jpg)\n",
    "\n",
    "This is a second part of the Sample SuperStore, Pandas & Python EDA tutorial. If you haven't yet alreeady gone through the first part of this tutorial, I strongly encourage you to read the first part. A lot of fundemental aspects covering the basic instructions around Python and Pandas, much like loading the libraries and understanding the dataset in gengeral have already been covered. Given that this is a second part of this Jupyter notebook tutorial, we will try to clean-up the data from invalid values, and manipulate them further to our business needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Library\n",
    "\n",
    "Since we'll be starting again with a fresh new Jupyter Notebook file, we need to load-up the library again to our environment. On the first part of this tutorial, we have covered this aspect and it's basically a continuation from our previous tutorial. Once that you type the following `import pandas as pd` to your Jupyter Notebook, Pandas is loaded once again and is ready for some action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read CSV File \n",
    "\n",
    "The following code would imply these instructions\n",
    "\n",
    "- *`df_cleaned`* = is the name of the variable, that will be using throughout the example of this tutorial.\n",
    "- *`pd`* = stands for Panda\n",
    "- *`.read_csv`* = is a method within to read the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try to read from the new order dataset\n",
    "df_cleaned = pd.read_csv('data/df_orders_exported.csv', index_col='Order ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OrderDate</th>\n",
       "      <th>ShipDate</th>\n",
       "      <th>ShipMode</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>CustomerName</th>\n",
       "      <th>Segment</th>\n",
       "      <th>Country</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>PostalCode</th>\n",
       "      <th>Region</th>\n",
       "      <th>ProductID</th>\n",
       "      <th>Category</th>\n",
       "      <th>SubCategory</th>\n",
       "      <th>ProductName</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Order ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CA-2017-152156</th>\n",
       "      <td>2017-11-08</td>\n",
       "      <td>2017-11-11</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>CG-12520</td>\n",
       "      <td>Claire Gute</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>42420.0</td>\n",
       "      <td>South</td>\n",
       "      <td>FUR-BO-10001798</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Bookcases</td>\n",
       "      <td>Bush Somerset Collection Bookcase</td>\n",
       "      <td>261.9600</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>41.9136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA-2017-152156</th>\n",
       "      <td>2017-11-08</td>\n",
       "      <td>2017-11-11</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>CG-12520</td>\n",
       "      <td>Claire Gute</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>42420.0</td>\n",
       "      <td>South</td>\n",
       "      <td>FUR-CH-10000454</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Chairs</td>\n",
       "      <td>Hon Deluxe Fabric Upholstered Stacking Chairs,...</td>\n",
       "      <td>731.9400</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>219.5820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA-2017-138688</th>\n",
       "      <td>2017-06-12</td>\n",
       "      <td>2017-06-16</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>DV-13045</td>\n",
       "      <td>Darrin Van Huff</td>\n",
       "      <td>Corporate</td>\n",
       "      <td>United States</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>California</td>\n",
       "      <td>90036.0</td>\n",
       "      <td>West</td>\n",
       "      <td>OFF-LA-10000240</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Labels</td>\n",
       "      <td>Self-Adhesive Address Labels for Typewriters b...</td>\n",
       "      <td>14.6200</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.8714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US-2016-108966</th>\n",
       "      <td>2016-10-11</td>\n",
       "      <td>2016-10-18</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>SO-20335</td>\n",
       "      <td>Sean O'Donnell</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Fort Lauderdale</td>\n",
       "      <td>Florida</td>\n",
       "      <td>33311.0</td>\n",
       "      <td>South</td>\n",
       "      <td>FUR-TA-10000577</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Tables</td>\n",
       "      <td>Bretford CR4500 Series Slim Rectangular Table</td>\n",
       "      <td>957.5775</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.45</td>\n",
       "      <td>-383.0310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US-2016-108966</th>\n",
       "      <td>2016-10-11</td>\n",
       "      <td>2016-10-18</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>SO-20335</td>\n",
       "      <td>Sean O'Donnell</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Fort Lauderdale</td>\n",
       "      <td>Florida</td>\n",
       "      <td>33311.0</td>\n",
       "      <td>South</td>\n",
       "      <td>OFF-ST-10000760</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Storage</td>\n",
       "      <td>Eldon Fold 'N Roll Cart System</td>\n",
       "      <td>22.3680</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2.5164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US-2018-147886</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US-2018-147998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US-2018-151127</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US-2018-155999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US-2018-155999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10800 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 OrderDate    ShipDate        ShipMode CustomerID  \\\n",
       "Order ID                                                            \n",
       "CA-2017-152156  2017-11-08  2017-11-11    Second Class   CG-12520   \n",
       "CA-2017-152156  2017-11-08  2017-11-11    Second Class   CG-12520   \n",
       "CA-2017-138688  2017-06-12  2017-06-16    Second Class   DV-13045   \n",
       "US-2016-108966  2016-10-11  2016-10-18  Standard Class   SO-20335   \n",
       "US-2016-108966  2016-10-11  2016-10-18  Standard Class   SO-20335   \n",
       "...                    ...         ...             ...        ...   \n",
       "US-2018-147886         NaN         NaN             NaN        NaN   \n",
       "US-2018-147998         NaN         NaN             NaN        NaN   \n",
       "US-2018-151127         NaN         NaN             NaN        NaN   \n",
       "US-2018-155999         NaN         NaN             NaN        NaN   \n",
       "US-2018-155999         NaN         NaN             NaN        NaN   \n",
       "\n",
       "                   CustomerName    Segment        Country             City  \\\n",
       "Order ID                                                                     \n",
       "CA-2017-152156      Claire Gute   Consumer  United States        Henderson   \n",
       "CA-2017-152156      Claire Gute   Consumer  United States        Henderson   \n",
       "CA-2017-138688  Darrin Van Huff  Corporate  United States      Los Angeles   \n",
       "US-2016-108966   Sean O'Donnell   Consumer  United States  Fort Lauderdale   \n",
       "US-2016-108966   Sean O'Donnell   Consumer  United States  Fort Lauderdale   \n",
       "...                         ...        ...            ...              ...   \n",
       "US-2018-147886              NaN        NaN            NaN              NaN   \n",
       "US-2018-147998              NaN        NaN            NaN              NaN   \n",
       "US-2018-151127              NaN        NaN            NaN              NaN   \n",
       "US-2018-155999              NaN        NaN            NaN              NaN   \n",
       "US-2018-155999              NaN        NaN            NaN              NaN   \n",
       "\n",
       "                     State  PostalCode Region        ProductID  \\\n",
       "Order ID                                                         \n",
       "CA-2017-152156    Kentucky     42420.0  South  FUR-BO-10001798   \n",
       "CA-2017-152156    Kentucky     42420.0  South  FUR-CH-10000454   \n",
       "CA-2017-138688  California     90036.0   West  OFF-LA-10000240   \n",
       "US-2016-108966     Florida     33311.0  South  FUR-TA-10000577   \n",
       "US-2016-108966     Florida     33311.0  South  OFF-ST-10000760   \n",
       "...                    ...         ...    ...              ...   \n",
       "US-2018-147886         NaN         NaN    NaN              NaN   \n",
       "US-2018-147998         NaN         NaN    NaN              NaN   \n",
       "US-2018-151127         NaN         NaN    NaN              NaN   \n",
       "US-2018-155999         NaN         NaN    NaN              NaN   \n",
       "US-2018-155999         NaN         NaN    NaN              NaN   \n",
       "\n",
       "                       Category SubCategory  \\\n",
       "Order ID                                      \n",
       "CA-2017-152156        Furniture   Bookcases   \n",
       "CA-2017-152156        Furniture      Chairs   \n",
       "CA-2017-138688  Office Supplies      Labels   \n",
       "US-2016-108966        Furniture      Tables   \n",
       "US-2016-108966  Office Supplies     Storage   \n",
       "...                         ...         ...   \n",
       "US-2018-147886              NaN         NaN   \n",
       "US-2018-147998              NaN         NaN   \n",
       "US-2018-151127              NaN         NaN   \n",
       "US-2018-155999              NaN         NaN   \n",
       "US-2018-155999              NaN         NaN   \n",
       "\n",
       "                                                      ProductName     Sales  \\\n",
       "Order ID                                                                      \n",
       "CA-2017-152156                  Bush Somerset Collection Bookcase  261.9600   \n",
       "CA-2017-152156  Hon Deluxe Fabric Upholstered Stacking Chairs,...  731.9400   \n",
       "CA-2017-138688  Self-Adhesive Address Labels for Typewriters b...   14.6200   \n",
       "US-2016-108966      Bretford CR4500 Series Slim Rectangular Table  957.5775   \n",
       "US-2016-108966                     Eldon Fold 'N Roll Cart System   22.3680   \n",
       "...                                                           ...       ...   \n",
       "US-2018-147886                                                NaN       NaN   \n",
       "US-2018-147998                                                NaN       NaN   \n",
       "US-2018-151127                                                NaN       NaN   \n",
       "US-2018-155999                                                NaN       NaN   \n",
       "US-2018-155999                                                NaN       NaN   \n",
       "\n",
       "                Quantity  Discount    Profit  \n",
       "Order ID                                      \n",
       "CA-2017-152156       2.0      0.00   41.9136  \n",
       "CA-2017-152156       3.0      0.00  219.5820  \n",
       "CA-2017-138688       2.0      0.00    6.8714  \n",
       "US-2016-108966       5.0      0.45 -383.0310  \n",
       "US-2016-108966       2.0      0.20    2.5164  \n",
       "...                  ...       ...       ...  \n",
       "US-2018-147886       NaN       NaN       NaN  \n",
       "US-2018-147998       NaN       NaN       NaN  \n",
       "US-2018-151127       NaN       NaN       NaN  \n",
       "US-2018-155999       NaN       NaN       NaN  \n",
       "US-2018-155999       NaN       NaN       NaN  \n",
       "\n",
       "[10800 rows x 19 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10800, 19)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the total rows and columns number\n",
    "df_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the total rows and columns default numbers.\n",
    "pd.set_option('display.max_columns', 21)\n",
    "pd.set_option('display.max_rows', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.columns = ['OrderID','OrderDate', 'ShipDate', 'ShipMode', 'CustomerID', 'CustomerName', 'Segment' , 'Country', 'City', 'State', 'PostalCode', 'Region', 'ProductID', 'Category', 'SubCategory', 'ProductName' , 'Sales', 'Quantity', 'Discount', 'Profit']\n",
    "# Let's try to rename the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10800 entries, 0 to 10799\n",
      "Data columns (total 20 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   OrderID       10800 non-null  object \n",
      " 1   OrderDate     9994 non-null   object \n",
      " 2   ShipDate      9994 non-null   object \n",
      " 3   ShipMode      9994 non-null   object \n",
      " 4   CustomerID    9994 non-null   object \n",
      " 5   CustomerName  9994 non-null   object \n",
      " 6   Segment       9994 non-null   object \n",
      " 7   Country       9994 non-null   object \n",
      " 8   City          9994 non-null   object \n",
      " 9   State         9994 non-null   object \n",
      " 10  PostalCode    9983 non-null   float64\n",
      " 11  Region        9994 non-null   object \n",
      " 12  ProductID     9994 non-null   object \n",
      " 13  Category      9994 non-null   object \n",
      " 14  SubCategory   9994 non-null   object \n",
      " 15  ProductName   9994 non-null   object \n",
      " 16  Sales         9994 non-null   float64\n",
      " 17  Quantity      9994 non-null   float64\n",
      " 18  Discount      9994 non-null   float64\n",
      " 19  Profit        9994 non-null   float64\n",
      "dtypes: float64(5), object(15)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Let's check the head dataset values.\n",
    "df_cleaned.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check wheter or not we have empty cells/records in our dataset.\n",
    "\n",
    "The following code would imply these instructions\n",
    "\n",
    "- *df_orders* = is the name of the variable, that will be using throughout the example of this tutorial.\n",
    "- *.info()* = is the method to print the coloumns data type and cells number in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's print the columns data types, along with the NaN records in the dataset and the number of cells in them.\n",
    "df_cleaning.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RangeIndex: **10.800** entries, from 0 to 10799.\n",
    "- Data columns (**total 21 columns**):\n",
    "\n",
    "Range index would give us information on how many rows on the dataset, while for the data column would give us information on how many columns available. For the **Non-Null Count number** would give us the Valid records number. So to identify the missing records/cell, would be to subtract the RangeIndex entries, with the remaining of the records available.\n",
    "\n",
    "And also, as you can see from the previous list, we need to change the following column data types, from:\n",
    "\n",
    "- OrderDate : *Object*\n",
    "- ShipDate : *Object*\n",
    "- PostalCode : *Object*\n",
    "\n",
    "to\n",
    "\n",
    "- OrderDate : *DateTime*\n",
    "- ShipDate : *DateTime*\n",
    "- PostalCode : *Object*\n",
    "\n",
    "Since those column don't have an appropriate data types definition yet. That's why we need to change them, so we could manipulate them better on the next session.\n",
    "\n",
    "The following code would imply these instructions\n",
    "- *df_orders* = is the name of the variable, that will be using throughout the example of this tutorial.\n",
    "- *.astype()* = is the method to display the data types from the dataset available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try to check, if the current dataset has any potential invalid data in them?\n",
    "\n",
    "The following code would imply these instructions\n",
    "\n",
    "- *df_cleaning* = is the name of the variable, that will be using throughout the example of this tutorial.\n",
    "- *.isnull()* = is the method name, to check if not we have any invalids values in the dataset.\n",
    "- Note = this method would result in *True* or *False* output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaning.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Clean-up the Invalid Records in The Dataset\n",
    "\n",
    "So that we know from the above table, we have rows of invalid values within our tables (indicated by the '*True*' values, and we wish to do further analysis in them, it'd be best to remove them so we could get finer overview with the remaining of the table values.\n",
    "\n",
    "The following code would imply these instructions:\n",
    "\n",
    "- *df_cleaning* = is the name of the variable, that will be using throughout the example of this tutorial.\n",
    "- *.dropna()* = is the method name, to remove the invalid records within our dataset.\n",
    "- *['OrderDate]* = is the coloumn that we wish to check the invalid values from.\n",
    "- *inplace=True* = since we'd like to have them in a new dataset, we need to pass the value set to '*True*', that way it'd reflect on the new dataset. Otherwise if we pass the value of '*False*', it only stays on the **memory storage**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, let's try to drop missing or invalied values.\n",
    "# df_cleaning.dropna(subset=['OrderDate'], inplace=True)\n",
    "df_cleaning.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's do a quick check with the recent dataset, if everything marks with 'False', then everything is clear!\n",
    "df_cleaning.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making changes to data!\n",
    "## Let's Add Additional Column Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try to create the Revenue Column!\n",
    "df_cleaning['Revenue'] = df_cleaning['Sales'] - df_cleaning['Profit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaning.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try to create the (Gross) Price Column!\n",
    "df_cleaning['GrossPrice'] = (df_cleaning['Revenue'] - df_cleaning['Profit']) / df_cleaning['Quantity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaning.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try to create the (Net)Price Column!\n",
    "df_cleaning['NetPrice'] = df_cleaning['GrossPrice'] - (df_cleaning['GrossPrice'] * df_cleaning['Discount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaning.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaning.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the coloumn, 'GrossPrice' & 'Price'!\n",
    "df_cleaning = df_cleaning.drop(columns=['GrossPrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting Dataset\n",
    "\n",
    "Once that we've satisfied with out results, let's export them a new CSV dataset, so we could work with them on the next notebook.\n",
    "\n",
    "*- df_cleaning* = is the name of the variable, that will be using throughout the example of this tutorial.\n",
    "*- .to_csv* = is the export method to a CSV dataset.\n",
    "\n",
    "### From let's import them from previous superstore.csv to df_orders.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaning.to_csv('df_cleaning.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
